# Attribution and Copyright Notices

This project uses the following open-source models and libraries:

## OpenAI Whisper

We use the [Whisper](https://github.com/openai/whisper) speech recognition system for transcription.

**License:** MIT License

**Copyright:** OpenAI

```text
MIT License

Copyright (c) 2022 OpenAI
```

## pyannote.audio

We use the [pyannote.audio](https://github.com/pyannote/pyannote-audio) library for speaker diarization.

**License:** MIT License

**Copyright:** Hervé Bredin

```text
MIT License

Copyright (c) 2018-present Hervé Bredin
```

## pyannote/speaker-diarization-3.1

We use the pre-trained speaker diarization model from pyannote.

**License:** MIT License

**Model:** [pyannote/speaker-diarization-3.1](https://huggingface.co/pyannote/speaker-diarization-3.1)

**Copyright:** Hervé Bredin

## pyannote/segmentation-3.0

We use the pre-trained segmentation model from pyannote.

**License:** MIT License

**Model:** [pyannote/segmentation-3.0](https://huggingface.co/pyannote/segmentation-3.0)

**Copyright:** Hervé Bredin

## Other Dependencies

This project also uses the following libraries:

- **yt-dlp**: Video downloading (Unlicense or Public Domain)
- **torch**: Deep learning framework (BSD-style license)
- **torchaudio**: Audio processing (BSD-style license)
- **torchcodec**: Audio codec (various licenses)
- **click**: CLI framework (BSD 3-Clause License)
- **tqdm**: Progress bars (MIT License)
- **ffmpeg-python**: FFmpeg Python bindings (Apache 2.0)
- **soundfile**: Audio file I/O (BSD 3-Clause License)

All dependencies are open-source and allow commercial use.

## How to Use This Project

When using this project commercially, you must:

1. Retain the original MIT license notice
2. Include this ATTRIBUTION.md file
3. Acknowledge OpenAI (Whisper) and pyannote.audio in your documentation
4. Comply with Bilibili's terms of service when downloading content
